{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593d1390-fdbd-4536-871d-d826af4e8b5a",
   "metadata": {},
   "source": [
    "# Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a74eee-6fcb-4446-a6e0-83f8b500b3c1",
   "metadata": {},
   "source": [
    "Grid Search CV (Cross-Validation) is a technique used in machine learning for hyperparameter tuning. It helps find the optimal hyperparameters for a machine learning model by systematically searching through a predefined set of hyperparameter combinations and evaluating each combination's performance using cross-validation. The primary purposes of Grid Search CV.\n",
    "\n",
    "Grid Search: Grid Search CV performs an exhaustive search over all possible combinations of hyperparameters from the defined grid. For each combination, it trains the model on the training data using cross-validation and calculates a performance metric (e.g., accuracy, F1-score, or mean squared error) on the validation fold(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a50aeb-1f97-4282-bcd6-63af09b375f1",
   "metadata": {},
   "source": [
    "# Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99122af1-d6b2-40f1-954d-ef839445c6a7",
   "metadata": {},
   "source": [
    "Grid Search CV and Randomized Search CV are both techniques for hyperparameter tuning in machine learning, but they differ in how they explore and search the hyperparameter space. Here's a description of the differences between them and when you might choose one over the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b27351b-0bfd-4055-b140-267764eb6027",
   "metadata": {},
   "source": [
    "# Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7c56a-c82d-4941-b813-ced953e136bc",
   "metadata": {},
   "source": [
    "Data leakage, also known as information leakage or leakage, is a critical problem in machine learning where information from outside the training dataset is inadvertently used to train a model or make predictions. Data leakage can lead to overly optimistic performance estimates during model development and can result in models that perform poorly on new, unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd4631-50d2-40ce-b30e-5ad355527a09",
   "metadata": {},
   "source": [
    "# Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d194d-3014-4df5-8395-623c55d33519",
   "metadata": {},
   "source": [
    "Preventing data leakage is crucial when building a machine learning model to ensure that the model's performance estimates are reliable, and it can generalize effectively to new, unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa7bb6-e38f-4498-92a4-082efdf62d91",
   "metadata": {},
   "source": [
    "# Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768e440a-d0f2-4d25-820b-8a99a1c0ee23",
   "metadata": {},
   "source": [
    "A confusion matrix is a table or matrix used in classification to assess the performance of a machine learning model. It provides a summary of the model's predictions compared to the actual ground truth labels. A confusion matrix is particularly useful for evaluating the performance of binary and multiclass classification models. It is also a fundamental tool for calculating various performance metrics such as accuracy, precision, recall, and F1-score. A typical confusion matrix has the following components:\n",
    "\n",
    "True Positives (TP): The number of instances correctly predicted as positive (correctly classified as the positive class).\n",
    "\n",
    "True Negatives (TN): The number of instances correctly predicted as negative (correctly classified as the negative class).\n",
    "\n",
    "False Positives (FP): The number of instances incorrectly predicted as positive (incorrectly classified as the positive class when they are actually negative). Also known as Type I errors.\n",
    "\n",
    "False Negatives (FN): The number of instances incorrectly predicted as negative \n",
    "\n",
    "\n",
    "Accuracy= TP+FP+FN+TN TP+TN\n",
    "â€‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6278662-295a-4bfd-a021-d8235a71390b",
   "metadata": {},
   "source": [
    "# Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38038e35-fd03-4bad-a289-eab91d508555",
   "metadata": {},
   "source": [
    "if FP is impontant then we used precision but if FN is impontant then we use recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219c1f4-7718-410d-9186-1425e125f62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
