{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef7ff6a-4f5a-4658-9cc9-a6aa9f411b90",
   "metadata": {},
   "source": [
    "# Q1. What is the mathematical formula for a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0c04c-c8b2-4e0a-bbfe-906d04a854b5",
   "metadata": {},
   "source": [
    "w * x + b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23093e-f1e9-443a-946b-91cc863acfb0",
   "metadata": {},
   "source": [
    "# Q2. What is the objective function of a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb84c1d-06e5-47b1-a91e-c55574e39189",
   "metadata": {},
   "source": [
    "1/2 * ||w||^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26202ed3-e2df-411b-8a5d-2287f78b89a9",
   "metadata": {},
   "source": [
    "# Q3. What is the kernel trick in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57558091-b901-4243-b018-cd043d665105",
   "metadata": {},
   "source": [
    "The kernel trick is a powerful technique used in Support Vector Machines (SVMs) and other machine learning algorithms .\n",
    "Linear Kernel (Identity Kernel): This is the default kernel, and it represents a linear transformation. It doesn't change the feature space; it just computes the dot product between the original feature vectors.\n",
    "\n",
    "Polynomial Kernel: The polynomial kernel maps data into a higher-dimensional space using polynomial functions. It introduces nonlinearity into the SVM by considering not only linear relationships but also higher-order interactions between features.\n",
    "\n",
    "Radial Basis Function (RBF) Kernel: The RBF kernel, also known as the Gaussian kernel, is widely used for SVMs. It maps data into an infinite-dimensional space and is capable of capturing highly complex, nonlinear decision boundaries.\n",
    "\n",
    "Sigmoid Kernel: The sigmoid kernel is another nonlinear kernel function that maps data into a higher-dimensional space. It is often used in applications like neural network-inspired SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1109d-5feb-4052-b973-bf3b87b5b81f",
   "metadata": {},
   "source": [
    "# Q4. What is the role of support vectors in SVM Explain with example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2fd5d-f5ae-4e5f-86af-8fc4f07b74d3",
   "metadata": {},
   "source": [
    "Support vectors play a crucial role in Support Vector Machines (SVMs). They are the data points in the training set that are closest to the decision boundary, and they are instrumental in defining the decision boundary itself. These vectors are the most challenging and informative data points for the SVM, as they have the smallest margin and are often referred to as \"support\" because they support the placement of the decision boundary.\n",
    "\n",
    "Here's how support vectors work and their role in SVMs, illustrated with an example:\n",
    "\n",
    "Suppose you have a binary classification problem where you want to classify images of animals into two categories: \"cats\" and \"dogs.\" Your data consists of various features extracted from these images, such as pixel values, color histograms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990fd5d-917a-4ece-afe1-05a5588647d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
